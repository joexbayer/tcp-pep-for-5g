\documentclass[a4paper,english, 11pt]{report}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{uiomasterfp}
\usepackage{url}
\author{Joe Bayer}
\title{TCP PEP}
\subtitle{Extension of a TCP Performance Enhancing Proxy to
Support Non-interactive Applications}

\begin{document}
\uiomasterfp[program={Informatics: Programming and System Architecture}, supervisors={Michael Welzl\and Kristjon Ciko}]

\tableofcontents

\chapter{Intro}

\chapter{Background}

\section{Future of wireless communication.}
The future of wireless communication has seen a lot of improvements such as...
... highly increased bandwidth ... using Millimetre frequency bands ... but at the cost of Highly fluctuating bandwidth with wireless networks, especially with higher frequencies.\\ 

\subsection{5G Millimetre Wave}
The emergence of 5G Millimeter wave communications has opened the doors for low latency networks with multiple gigabit bandwidth. This is achieved by using higher millimetre wave (mmWave) frequencies in the range of 30GHz to 300GHz, which as a lot of benefits. ~\cite{Agrawal_Sharma_2016} A wider spectrum of frequencies to choose from and higher data transfer are just some of the many benefits mmWave provides. But along side the benefits, mmWave has also introduced a lot of new challenges.\\

A big problem with millimetre wave communication is signal path blocking also called "Line of sight blocking"~\cite{mmwave_blocking}. This is were ...
Even the human body can create enough blockage to drastically reduce the bandwidth. 

[Figure from mmwave paper showing bandwith fluctuations.]

''To achieve high throughput as well as low latency, these
wireless networks will rely heavily on millimeter wave frequency bands (30-300 GHz), due to the large amounts of
spectrum available on those bands.'' (qoute mmwave paper)

''Applications that require extremely low latency are
expected to be a major driver of 5G and WLAN networks that
include millimeter wave (mmWave) links.'' (qoute mmwave paper)

''Verizonâ€™s mmWave network deployed in
Minneapolis and Chicago reported a high handover frequency
due to frequent disruptions in mmWave connectivity''(cite A First Look at Commercial 5G Performance on Smartphones)

\subsection{Buffering}
\subsubsection{Buffer bloat}
The buffer bloat problem occurs when the systems between the endpoints buffer so many packets that the latency drastically increases and the reliability of the network as a whole goes down.{https://lwn.net/Articles/507065/} The (AD HOC) crude but simple solution was to just decrease all buffer sizes. Although this works in most cases, its far from a optimal solution. The increased latency is detrimental for interactive (latency sensitive) applications. Generally its preferred to drop packets and keep buffers small to avoid buffering time sensitive packets such as SYN packets.\\\\

Most focus has been on (helping? Supporting?) latency sensitive applications like virtual reality or remote surgery to name a few. This thesis will explore non-interactive applications where latency is not that critical and more buffering is acceptable and most likely desirable. By splitting traffic into interactive and non-interactive we can improve the performance of both. By having very small buffers for interactive applications we avoid bufferbloat problems, while utilizing the benefits of big buffers for non-interactive applications.

\subsubsection{FQ\_CODEL}
Fair Queue

\subsection{Non-Interactive Applications}
Non-Interactive applications such as Web traffic, File transfers and Videos? can benefit from larger buffering, especially with fluctuating bandwidths. Being able to have packets buffered for when the bandwidth is high will decrease delay times. (need citation or prove it myself?). At the same time, interactive applications will not suffer under large queue delays.

\section{TCP/IP (Move to top?}
(Get inspired by intro of tcp transport converter)
Perhaps the most well known internet transport protocol is the Transmission Control Protocol (TCP). It provides reliable and in order delivery of packets using acknowledgments (ACKs) and re-transmissions. ~\cite{Eddy_2022}
Interactive traffic uses TCP? {source}
End to end argument. Bad?
TCP handshake, reduce RTTs but using TCP Fast Open. Mostly short flows (cite)
\\
End to End congestion controller not very suited for highly fluctuating bandwidth.(cite David Hayes?)

\subsection{3 Way handshake (0 RTT)}
For TCP to establish a connection it uses a three-way handshake. First it sends a synchronization (SYN) packet to the desired endpoint. The endpoint answers with a acknowledgement and a synchronization packet of its own (SYN/ACK). And finally the client responds with a acknowledgment (ACK). At this point both endpoints have confirmed that they are ready for further communication. For any connection to be established this handshake has to be done. If we introduce a proxy we will need two handshakes, one for the initial connection and one for the connection from he proxy to the endpoint.

\subsection{TCP Fast Open}
A TCP connection can be configured with optional header extensions called TCP Options. 
Short flows terminating in a few round-trips. Meaning the "bottleneck" is the required initial TCP handshake.\\
TCP Fast Open allows data being exchanged during the handshake. 

Allow "syn fowarding" with TCP Fast Open creating a 0RTT increase when connecting through a proxy.
0RTT Transport Converter ~\cite{rfc8803}.


\section{PEPs}
A performance enhancing proxy (PEP) is a (connection splitting) proxy designed to increase performance of applications using it. Already in use! (satelites, cite). Inherently increases performance? (cite)
More logic inside the networks. Domain splitting and 0RTT.

\subsection{Transparent vs Non-Transparent}
A big discussion regarding PEPs has been if they should be transparent or non-transparent. Transparent PEPs are not visible to the applications that use it. They silently split the connections and spoof the IP-address of both the client and server~\cite{pep_dna}.. (SIDE EFFECTS). Non-Transparent PEPs on the other hand are explicitly chosen by either the client or the server, and the sender is aware of the proxy splitting the original connection. This approach can be seen as more ethical and "correct" (FIND BETTER WORDING), but modifications at the sender side become necessary to utilize the PEP.

\section{Kernel Modules}
LKM (Loadable Kernel Modules), "program" running inside the Linux kernel.
Userspace vs Kernel. Reduce system call overhead.
\subsection{System Calls}
Reduce over head from userspace -> kernel system calls.

\chapter{Implementation | Design}

{Table of design decisions based on different PEP implementations compared to ours.}
{0RTT, Transparent, Using TLV, Special ACKS, connection splitting.}\\
\begin{tabular}{ |p{4cm}||p{2cm}|p{2cm}|p{2cm}|p{2cm}| }
 \hline
 \multicolumn{5}{|c|}{Country List} \\
 \hline
 Implementation& 0Rtt &Connection Splitting &Special ACKs &Transparent\\
 \hline
 Afghanistan   & AF    &AFG&   004 & x\\
 Aland Islands&   AX  & ALA   &248 & x\\
 Albania &AL & ALB&  008 & x\\
 Algeria    &DZ & DZA&  012& x \\
 American Samoa&   AS  & ASM&016& x\\
 Andorra& AD  & AND   &020& x\\
 Angola& AO  & AGO&024& x\\
 \hline
\end{tabular}

\chapter{Evaluation}
\chapter{Conclusion}

\bibliography{myBib.bib}{}
\bibliographystyle{plain}
\end{document}s